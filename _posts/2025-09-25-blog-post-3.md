---
title: 'Blog 3: Exception to Data Driven Rules'
date: 2025-09-25
permalink: /posts/2025/09/blog-post-3/
tags:
  - Data
  - Machine Learning
  - News
---

The problem with Data-Driven rules

**News Article:**  
[The Right to Be an Exception to a Data-Driven Rule](https://mit-serc.pubpub.org/pub/right-to-be-exception/release/2)

---
1.What is a data-driven rule, and what does it mean to be a data-driven exception? Is an exception the same as an error? 

A data driven rule is some method of sorting that looks at a collection of data with different variables and analyzes which group a case is sorted into like interview or no interview. A data-driven exception is when a case is sorted into a group that it does not belong in. An exception is the same as an error because it shows that the rule is not perfect and has some flaws to its criteria.

2.In addition to those listed above, what other factors differentiate data-driven decisions from human ones?

As the article states, humans go through the process slowly, and make mistakes in a diverse way. If 10 humans review someone’s resume, chances are someone will like it, but if 10 computers use data-driven rules, it will most likely be rejected or accepted 10 times.

3.Beyond what is discussed above, what are some of the benefits and downsides of individualization? 

Individualization adds more nuance to the data-driven rule, in hopes of creating a more suitable rule for everyone. This can improve performance by giving a better accuracy to the sorting. However, as the article states, you can end up overfitting; “performing extremely well in training but poorly when deployed.”

4.Why is uncertainty so critical to the right to be an exception? When the stakes are high (e.g., in criminal sentencing), is there any evaluation metric (e.g., accuracy) that can justify the use of a data-driven rule without the consideration of uncertainty?

Because uncertainty is important to think about when the risk is high. If a data-driven rule is being used for things like insurance or sentences, the risk is high, and no amount of individualization will get the accuracy high enough. I don’t believe that any metric such as accuracy can warrant the uncertainty that comes with a data-driven rule. If a risk is low, having uncertainty is fine, but as risk grows, uncertainty is increasingly dangerous.

My discussion question: Is it possible to train data-driven rules with human input to correct mistakes? If so, how can we eliminate bias from data-driven rules with human guidance? I chose this question because I was interested in how we can make data-driven rules more safe to use when they are chosen to be used.

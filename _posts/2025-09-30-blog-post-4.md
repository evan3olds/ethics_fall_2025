---
title: 'Blog 4: How GenAI Works'
date: 2025-09-30
permalink: /posts/2025/09/blog-post-4/
tags:
  - AI
  - Data
  - News
---

GenAI's use of creative work

**News Article:**  
[How Generative AI Works and How It Fails](https://mit-serc.pubpub.org/pub/f3o5mpn6/release/1?readingCollection=3a6c54f1)

Brief Summary
---
This article talks about what AI is really doing when it is generating "new" information. It also talks about the ethical issues with AI usage, including cheap harmful labor and harmful language.

Discussion Questions: 'The use of creative work for training'
---
1.How can those who want to change the system go about doing so? 

ㅤㅤThose who want to change the system can make change by voicing their opinions and getting many people to bring about new policies. If we had better regulations on what companies can use for data-training, we would be able to eliminate the plagiarism that comes with generative AI. Some people have already gone about making change, implementing pixels or secret messages in their art that makes it impossible to use as data. This would theoretically prevent people's work from being used and plagiarised by GenAI.

2.Can the market solve the problem, such as through licensing agreements between publishers and AI companies? 

ㅤㅤYes, if publishers had an incentive to let AI companies use their work for data-training, they would have more freedom to choose whether or not their work is going to be used for reasons they don't want. A possible solution would be to have some sort of indication on whether or not a publisher's work is public domain, or if they do not want their creative work stolen.

3.What about copyright law — either interpreting existing law or by updating it? 

ㅤㅤUpdating copyright law could potentially benefit the sanctity of people's creative work. Reinterpreting current law in the context of AI would also help specify what they could mean for AI. There are currently many loopholes that LLM's exploit to get more data for their models. Making more concrete laws is increasingly necessary, with AI advancing at a rapid pace. 

4.What other policy interventions might be helpful?

ㅤㅤHolding LLM's accountable for plagiarism (albeit difficult), could help restore the public's view of AI, and also make sure that people's creative work is protected. There could also be more regulation on what things can be generated. If a model can label something, it could potentially figure out whether or not it is something ethical (such as deepfakes).

My Discussion Question
---

Is usage of GenAI for generating ideas better than just using the generation? How can we know if something is plagiarism if it's based on a generated photo?

I included this question because I think AI plagiarism is more in depth than meets the eye. If you ask AI to generate something for a project and you use the generated picture, it is most likely plagiarism of someone else's work. However, using AI to just generate ideas might seem ethical, but it's similar to reading someone else's essay and then writing your own essay heavily inspired by theirs. You end up using someone else's work to heavily influence your work, leading to problems of plagiarism.

Reflection
---

I think this activity was a good way to dive deeper into AI's effect on society and intellectual property, with people like publishers and artists at the forefront of the topic. The questions helped me think of possible ways that AI could be changed to better suit people who publish creative work. Generating my own question was helpful for thinking out of the box and finding caveats to the issue. 